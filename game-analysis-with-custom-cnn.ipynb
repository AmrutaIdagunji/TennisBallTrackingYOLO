{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7031196,"sourceType":"datasetVersion","datasetId":4044279}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Classifying visibility","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport cv2\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, Dataset, random_split\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-14T19:14:55.522300Z","iopub.execute_input":"2023-12-14T19:14:55.522723Z","iopub.status.idle":"2023-12-14T19:15:13.076208Z","shell.execute_reply.started":"2023-12-14T19:14:55.522683Z","shell.execute_reply":"2023-12-14T19:15:13.075150Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Check if GPU is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-12-14T19:15:13.077784Z","iopub.execute_input":"2023-12-14T19:15:13.079727Z","iopub.status.idle":"2023-12-14T19:15:13.090158Z","shell.execute_reply.started":"2023-12-14T19:15:13.079653Z","shell.execute_reply":"2023-12-14T19:15:13.089076Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport os\nimport pandas as pd\nimport numpy as np\n\nbase_dataset_path = \"/kaggle/input/gamedataset/Dataset\"\n\ninput_height = 128\ninput_width = 128\n\nimage_shape = (input_height, input_width)\n\nimages = []\nstatus = []\nfor i, game_folder in enumerate(os.listdir(base_dataset_path)):\n    game_path = os.path.join(base_dataset_path, game_folder)\n    if(game_folder != \"Readme.docx\"):\n        for clip_folder in os.listdir(game_path):\n            clip_path = os.path.join(game_path, clip_folder)\n            labels = pd.read_csv(os.path.join(clip_path, 'Label.csv'))\n\n            if(len(labels) < 200):\n                for _, row in labels.iterrows():\n                    if row['visibility'] > 0:\n                        image_path = os.path.join(clip_path, row['file name'])\n                        image = cv2.resize(cv2.imread(image_path, cv2.IMREAD_GRAYSCALE), (input_height, input_width))\n                        image = image.astype(np.float32)\n\n                        images.append(image)\n                        status.append(row['status'])\n                        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data = {'Path': images, 'Status': status}\ndf_training = pd.DataFrame(training_data)\ndf_training.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the dataset class\nclass GameDataset(Dataset):\n    def __init__(self, dataset):\n        self.dataset = dataset\n\n    def __getitem__(self, index):\n        return self.dataset.loc[index, 'Path'], self.dataset.loc[index, 'Status']\n\n    def __len__(self):\n        return len(self.dataset)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = GameDataset(df_training)\n\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\n\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\nbatch_size = 32\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BallTrackingCNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # [227x227x3] INPUT\n\n        self.conv1 = nn.Conv2d(1, 96, kernel_size=(11, 11), stride=4, padding=0)  # [55x55x96] CONV1: 96 11x11 filters at stride 4, pad 0\n        self.pool1 = nn.MaxPool2d(kernel_size=(3, 3), stride = 2) # [27x27x96] MAX POOL1: 3x3 filters at stride 2\n        self.norm1 = nn.BatchNorm2d(96)  # [27x27x96] NORM1: Normalization layer\n\n        self.conv2 = nn.Conv2d(96, 256, kernel_size=(5, 5), stride=1, padding=2) # [27x27x256] CONV2: 256 5x5 filters at stride 1, pad 2\n        self.drop1 = nn.Dropout(0.3)\n\n        self.pool2 = nn.MaxPool2d(kernel_size=(3, 3), stride = 2) # [13x13x256] MAX POOL2: 3x3 filters at stride 2\n        self.norm2 = nn.BatchNorm2d(256) # [13x13x256] NORM2: Normalization layer\n\n        self.conv3 = nn.Conv2d(256, 384, kernel_size=(3, 3), stride=1, padding=1)  # [13x13x384] CONV3: 384 3x3 filters at stride 1, pad 1\n        self.norm3 = nn.BatchNorm2d(384)\n\n        self.conv4 = nn.Conv2d(384, 384, kernel_size=(3, 3), stride=1, padding=1)  # [13x13x384] CONV4: 384 3x3 filters at stride 1, pad 1\n        self.norm4 = nn.BatchNorm2d(384)\n\n        self.conv5 = nn.Conv2d(384, 256, kernel_size=(3, 3), stride=1, padding=1)  # [13x13x256] CONV5: 256 3x3 filters at stride 1, pad 1\n        self.norm5 = nn.BatchNorm2d(256)\n\n        self.pool3 = nn.MaxPool2d(kernel_size=(3, 3), stride = 2)  # [6x6x256] MAX POOL3: 3x3 filters at stride 2\n\n        self.relu = nn.ReLU()\n        self.flat = nn.Flatten()\n        self.drop2 = nn.Dropout(0.5)\n\n        #self.fc6 = nn.Linear(9216, 4096)     \n        self.fc6 = nn.Linear(1024, 512)     \n        \n        #self.fc7 = nn.Linear(4096, 512)      \n        self.fc8 = nn.Linear(512, 4)        # output classes are 4\n\n    def forward(self, x):\n        x = self.pool1(self.relu(self.conv1(x))) \n        x = self.drop1(x)\n        x = self.pool2(self.relu(self.conv2(x))) \n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = self.pool3(self.relu(self.conv5(x))) \n        x = self.drop2(self.flat(x))\n        x = self.relu(self.fc6(x))\n        x = self.drop2(x)\n        #x = self.relu(self.fc7(x))\n        x = self.fc8(x)\n        return x\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, optimizer, loss_fn, n_epochs=50, early_stopping = False, plot_metrics = False):\n\n    for epoch in range(n_epochs):\n\n        train_loss = []\n        correct_train_pred = 0\n        \n        for inputs, labels in train_loader:\n            inputs =  inputs[:, np.newaxis, :, :].to(device)\n            labels = labels.to(device)\n            \n            y_pred = model(inputs)\n\n            pred_proba = nn.Softmax(dim=1)(y_pred)\n            prob_index = torch.argmax(pred_proba, dim=1)\n            prob_index = prob_index.float()\n\n            loss = loss_fn(pred_proba, labels.long())  # Convert labels to long type\n            train_loss.append(loss.item())\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            correct_train_pred += (prob_index == labels.data).sum().item()\n\n        train_acc = round((correct_train_pred / (len(train_loader) * batch_size)) * 100, 4)\n        train_loss = round(sum(train_loss)/(len(train_loader) * batch_size), 4)\n\n        val_loss = []\n        correct_val_pred = 0\n        for inputs, labels in val_loader:\n            inputs = inputs =  inputs[:, np.newaxis, :, :].to(device)\n            labels = labels.to(device)\n\n            y_pred = model(inputs)\n\n            pred_proba = nn.Softmax(dim=1)(y_pred)\n            prob_index = torch.argmax(pred_proba, dim=1)\n\n            prob_index = prob_index.float()\n            \n            loss = loss_fn(pred_proba, labels.long())  # Convert labels to long type\n            val_loss.append(loss.item())\n\n            correct_val_pred += (prob_index == labels.data).sum().item()\n\n        val_acc = round((correct_val_pred / (len(val_loader) * batch_size)) * 100, 4)\n        val_loss = round(sum(val_loss)/(len(val_loader) * batch_size), 4)\n\n        print(f'epoch {epoch + 1}, training accuracy: {train_acc}, training loss: {train_loss}, validation accuracy: {val_acc}, validation loss: {val_loss}')\n            \n    return model\n\nmodel = BallTrackingCNN().to(device)\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) #, weight_decay = 0.0005)\nn_epochs = 10\n\nmodel = train_model(model, optimizer, loss_fn, n_epochs)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Regressing x and y coordinates ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport os\nimport pandas as pd\nimport numpy as np\n\nbase_dataset_path = \"/kaggle/input/gamedataset/Dataset\"\n\ninput_height = 72\ninput_width = 128\n\nimage_shape = (input_height, input_width)\nclip_counts = {'game1': 13, 'game2': 8, 'game3': 9}\n\nheatmaps = []\nx_axis = []\ny_axis = []\nfor i, game_folder in enumerate(os.listdir(base_dataset_path)):\n    game_path = os.path.join(base_dataset_path, game_folder)\n    if(game_folder != \"Readme.docx\"):\n        for clip_folder in os.listdir(game_path):\n            clip_path = os.path.join(game_path, clip_folder)\n            labels = pd.read_csv(os.path.join(clip_path, 'Label.csv'))\n            \n            #if(len(labels) < 200):\n\n            for _, row in labels.iterrows():\n                if row['visibility'] > 0:\n                    image_path = os.path.join(clip_path, row['file name'])\n                    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n                    original_shape = image.shape\n\n                    image = cv2.resize(image, (input_height, input_width))\n                    image = image.astype(np.float32)\n                    heatmaps.append(image)\n\n                    # normalise the coordinate values by dividing them by the input shape\n                    x_axis.append(np.array([round(row['x-coordinate'] / (10 * input_width),4), round(row['y-coordinate'] / (10 * input_height), 4)]).astype(np.float32))\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T01:00:11.992494Z","iopub.execute_input":"2023-12-14T01:00:11.993521Z","iopub.status.idle":"2023-12-14T01:02:43.692858Z","shell.execute_reply.started":"2023-12-14T01:00:11.993480Z","shell.execute_reply":"2023-12-14T01:02:43.691799Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"training_data = {'Image': heatmaps, 'coord': x_axis}\ndf_training = pd.DataFrame(training_data)\ndf_training.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T01:02:59.815620Z","iopub.execute_input":"2023-12-14T01:02:59.816066Z","iopub.status.idle":"2023-12-14T01:03:00.404196Z","shell.execute_reply.started":"2023-12-14T01:02:59.816035Z","shell.execute_reply":"2023-12-14T01:03:00.403180Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"                                               Image             coord\n0  [[164.0, 170.0, 172.0, 172.0, 172.0, 176.0, 17...  [0.4492, 0.0847]\n1  [[164.0, 170.0, 172.0, 172.0, 172.0, 176.0, 17...  [0.4492, 0.0708]\n2  [[164.0, 171.0, 172.0, 172.0, 172.0, 176.0, 17...    [0.45, 0.0639]\n3  [[164.0, 171.0, 172.0, 172.0, 172.0, 176.0, 17...    [0.45, 0.0528]\n4  [[164.0, 171.0, 172.0, 172.0, 172.0, 176.0, 17...    [0.45, 0.0458]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image</th>\n      <th>coord</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[164.0, 170.0, 172.0, 172.0, 172.0, 176.0, 17...</td>\n      <td>[0.4492, 0.0847]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[164.0, 170.0, 172.0, 172.0, 172.0, 176.0, 17...</td>\n      <td>[0.4492, 0.0708]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[164.0, 171.0, 172.0, 172.0, 172.0, 176.0, 17...</td>\n      <td>[0.45, 0.0639]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[164.0, 171.0, 172.0, 172.0, 172.0, 176.0, 17...</td>\n      <td>[0.45, 0.0528]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[164.0, 171.0, 172.0, 172.0, 172.0, 176.0, 17...</td>\n      <td>[0.45, 0.0458]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Define the dataset class\nclass GameDataset(Dataset):\n    def __init__(self, dataset):\n        self.dataset = dataset\n\n    def __getitem__(self, index):\n        return self.dataset.loc[index, 'Image'], self.dataset.loc[index, 'coord']\n\n    def __len__(self):\n        return len(self.dataset)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T01:03:00.406436Z","iopub.execute_input":"2023-12-14T01:03:00.406831Z","iopub.status.idle":"2023-12-14T01:03:00.413363Z","shell.execute_reply.started":"2023-12-14T01:03:00.406799Z","shell.execute_reply":"2023-12-14T01:03:00.412158Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"dataset = GameDataset(df_training)\n\ntrain_size = int(0.7 * len(dataset))\nval_size = (len(dataset) - train_size) // 2 \ntrain_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, val_size])\n\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T01:05:43.908449Z","iopub.execute_input":"2023-12-14T01:05:43.908872Z","iopub.status.idle":"2023-12-14T01:05:43.917890Z","shell.execute_reply.started":"2023-12-14T01:05:43.908841Z","shell.execute_reply":"2023-12-14T01:05:43.916623Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass customTrackNet(nn.Module):\n    def __init__(self, input_height, input_width):\n        super(customTrackNet, self).__init__()\n        self.input_height = input_height\n        self.input_width = input_width\n\n        # Convolutional layers\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.pool2 = nn.MaxPool2d(2, 2)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.pool3 = nn.MaxPool2d(2, 2)\n        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n        self.pool4 = nn.MaxPool2d(2, 2)\n\n        # Fully connected layers\n        self.fc1 = nn.Linear(256 * (self.input_height // 16) * (self.input_width // 16), 512)\n        self.dropout1 = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(512, 256)\n        self.dropout2 = nn.Dropout(0.5)\n\n        # Output layer\n        self.fc3 = nn.Linear(256, 2)\n\n    def forward(self, x):\n        # Convolutional layers\n        x = F.relu(self.conv1(x))\n        x = self.pool1(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool2(x)\n        x = F.relu(self.conv3(x))\n        x = self.pool3(x)\n        x = F.relu(self.conv4(x))\n        x = self.pool4(x)\n\n        # Flatten the output\n        x = x.view(-1, 256 * (self.input_height // 16) * (self.input_width // 16))\n\n        # Fully connected layers\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n\n        # Output layer\n        x = F.softmax(self.fc3(x), dim=1)\n        return x\n\n# Create an instance of the TrackNet model\nmodel = customTrackNet(input_height, input_width)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T01:03:00.427044Z","iopub.execute_input":"2023-12-14T01:03:00.427482Z","iopub.status.idle":"2023-12-14T01:03:00.491571Z","shell.execute_reply.started":"2023-12-14T01:03:00.427448Z","shell.execute_reply":"2023-12-14T01:03:00.490245Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def train_model(model, optimizer, loss_fn, n_epochs=50, early_stopping = False, plot_metrics = False):\n    for epoch in range(n_epochs):\n        train_loss = []\n        correct_train_pred = 0\n        for inputs, labels in train_loader:\n\n            inputs = inputs[:, np.newaxis, :, :].to(torch.float).to(device)\n            labels = labels.to(device)\n\n            y_pred = model(inputs)\n            loss = loss_fn(y_pred, labels)\n            train_loss.append(loss.item())\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n        train_loss = round(sum(train_loss)/(len(train_loader) * batch_size), 4)\n\n        val_loss = []\n        correct_val_pred = 0\n        for inputs, labels in val_loader:\n\n            inputs = inputs[:, np.newaxis, :, :].to(torch.float).to(device)\n            labels = labels.to(device)\n\n            y_pred = model(inputs)\n            loss = loss_fn(y_pred, labels)\n            val_loss.append(loss.item())\n\n        val_loss = round(sum(val_loss)/(len(val_loader) * batch_size), 4)\n        print(f'epoch {epoch + 1}, training loss: {train_loss}, validation loss: {val_loss}')\n\n    return model\n\ntracknet_model = customTrackNet(input_height, input_width).to(device)\nloss_fn = nn.MSELoss()\noptimizer = optim.Adam(tracknet_model.parameters(), lr=0.0001)\nn_epochs = 20\n\n# Calculate the loss\ntracknet_model = train_model(tracknet_model, optimizer, loss_fn, n_epochs)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T01:03:00.494751Z","iopub.execute_input":"2023-12-14T01:03:00.495668Z","iopub.status.idle":"2023-12-14T01:05:11.680585Z","shell.execute_reply.started":"2023-12-14T01:03:00.495622Z","shell.execute_reply":"2023-12-14T01:05:11.679212Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"epoch 1, training loss: 0.001, validation loss: 0.0009\nepoch 2, training loss: 0.0009, validation loss: 0.0009\nepoch 3, training loss: 0.0009, validation loss: 0.0009\nepoch 4, training loss: 0.0008, validation loss: 0.0008\nepoch 5, training loss: 0.0008, validation loss: 0.0008\nepoch 6, training loss: 0.0007, validation loss: 0.0007\nepoch 7, training loss: 0.0007, validation loss: 0.0007\nepoch 8, training loss: 0.0007, validation loss: 0.0007\nepoch 9, training loss: 0.0006, validation loss: 0.0007\nepoch 10, training loss: 0.0006, validation loss: 0.0007\nepoch 11, training loss: 0.0006, validation loss: 0.0007\nepoch 12, training loss: 0.0006, validation loss: 0.0006\nepoch 13, training loss: 0.0006, validation loss: 0.0006\nepoch 14, training loss: 0.0006, validation loss: 0.0006\nepoch 15, training loss: 0.0006, validation loss: 0.0006\nepoch 16, training loss: 0.0006, validation loss: 0.0006\nepoch 17, training loss: 0.0006, validation loss: 0.0006\nepoch 18, training loss: 0.0006, validation loss: 0.0006\nepoch 19, training loss: 0.0006, validation loss: 0.0006\nepoch 20, training loss: 0.0006, validation loss: 0.0006\n","output_type":"stream"}]},{"cell_type":"code","source":"df_pred = df_training[-val_size:].reset_index(drop=True)\ndf_pred","metadata":{"execution":{"iopub.status.busy":"2023-12-14T01:41:33.326353Z","iopub.execute_input":"2023-12-14T01:41:33.326769Z","iopub.status.idle":"2023-12-14T01:41:34.293208Z","shell.execute_reply.started":"2023-12-14T01:41:33.326711Z","shell.execute_reply":"2023-12-14T01:41:34.292029Z"},"trusted":true},"execution_count":91,"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"                                                  Image             coord\n0     [[56.0, 48.0, 133.0, 3.0, 31.0, 27.0, 36.0, 39...  [0.5312, 0.3708]\n1     [[56.0, 48.0, 133.0, 3.0, 31.0, 27.0, 36.0, 39...     [0.518, 0.35]\n2     [[56.0, 48.0, 133.0, 3.0, 31.0, 27.0, 36.0, 39...  [0.5188, 0.3528]\n3     [[57.0, 48.0, 133.0, 3.0, 31.0, 27.0, 36.0, 39...  [0.5078, 0.3403]\n4     [[57.0, 48.0, 133.0, 3.0, 31.0, 27.0, 36.0, 39...  [0.4984, 0.3347]\n...                                                 ...               ...\n2861  [[84.0, 94.0, 82.0, 85.0, 71.0, 87.0, 72.0, 81...  [0.1859, 0.6639]\n2862  [[84.0, 94.0, 82.0, 85.0, 71.0, 87.0, 72.0, 81...  [0.1734, 0.6833]\n2863  [[84.0, 94.0, 82.0, 85.0, 71.0, 87.0, 72.0, 81...  [0.1602, 0.7111]\n2864  [[84.0, 94.0, 82.0, 85.0, 71.0, 87.0, 72.0, 81...  [0.1484, 0.7361]\n2865  [[84.0, 94.0, 82.0, 85.0, 71.0, 87.0, 72.0, 81...  [0.1344, 0.7639]\n\n[2866 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image</th>\n      <th>coord</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[56.0, 48.0, 133.0, 3.0, 31.0, 27.0, 36.0, 39...</td>\n      <td>[0.5312, 0.3708]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[56.0, 48.0, 133.0, 3.0, 31.0, 27.0, 36.0, 39...</td>\n      <td>[0.518, 0.35]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[56.0, 48.0, 133.0, 3.0, 31.0, 27.0, 36.0, 39...</td>\n      <td>[0.5188, 0.3528]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[57.0, 48.0, 133.0, 3.0, 31.0, 27.0, 36.0, 39...</td>\n      <td>[0.5078, 0.3403]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[57.0, 48.0, 133.0, 3.0, 31.0, 27.0, 36.0, 39...</td>\n      <td>[0.4984, 0.3347]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2861</th>\n      <td>[[84.0, 94.0, 82.0, 85.0, 71.0, 87.0, 72.0, 81...</td>\n      <td>[0.1859, 0.6639]</td>\n    </tr>\n    <tr>\n      <th>2862</th>\n      <td>[[84.0, 94.0, 82.0, 85.0, 71.0, 87.0, 72.0, 81...</td>\n      <td>[0.1734, 0.6833]</td>\n    </tr>\n    <tr>\n      <th>2863</th>\n      <td>[[84.0, 94.0, 82.0, 85.0, 71.0, 87.0, 72.0, 81...</td>\n      <td>[0.1602, 0.7111]</td>\n    </tr>\n    <tr>\n      <th>2864</th>\n      <td>[[84.0, 94.0, 82.0, 85.0, 71.0, 87.0, 72.0, 81...</td>\n      <td>[0.1484, 0.7361]</td>\n    </tr>\n    <tr>\n      <th>2865</th>\n      <td>[[84.0, 94.0, 82.0, 85.0, 71.0, 87.0, 72.0, 81...</td>\n      <td>[0.1344, 0.7639]</td>\n    </tr>\n  </tbody>\n</table>\n<p>2866 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"listPred = []\ndf_pred.loc[:, 'x'] = 0\ndf_pred.loc[:, 'y'] = 0\n\ncount = 0\nfor i, values in enumerate(test_loader):\n    inputs, _ = values\n    inputs = inputs[:, np.newaxis, :, :].to(torch.float).to(device)\n    y_pred = tracknet_model(inputs).cpu().detach().numpy()\n    size = len(y_pred)\n    \n    # 0 - x-coordinate, 1 - y-coordinate\n    for j in range(0:20):\n        print(y_pred[j, 0]  * input_width , df_pred.loc[j, 'coord'][0] *  input_width, y_pred[j, 1] * input_height , df_pred.loc[j, 'coord'][1] * input_height)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}